# -*- coding: utf-8 -*-

#Parameter for the metric tracking with neptune
neptune:
    project_name: "lukas.eisert/simclr"
    api: "eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vdWkubmVwdHVuZS5haSIsImFwaV91cmwiOiJodHRwczovL3VpLm5lcHR1bmUuYWkiLCJhcGlfa2V5IjoiNzI4NDUzNWQtODdhZi00NjAzLWJkMGYtOGZkYWEzZmJhYzUxIn0="
    tags: ["debug"]

#Parameters for the loading of the data from various sources
extract:
    MIN_STELLAR_MASS: 1e10
    MAX_STELLAR_MASS: 1e12
    SNAPSHOTS: [72, 78, 84, 91]
    DATASETS:
      #- "HSC_TNG50"
      - "HSC"
    FIELDS: 
      #- ["snapshot_id", "subhalo_id", "root_descendant_id",
      #   "lookback", "z",
      #   "stellar_age_2rhalf_lumw", "fraction_disk_stars",
      #   "stellar_mass", "mass_in_rad", "mass_exsitu", "half_mass_rad_physical",
      #   "snap_num_last_maj_merger", "mass_last_maj_merger",
      #   "mean_merger_lookback_time", "mean_merger_mass_ratio",
      #   "color", "i_band_mag_apparent", "i_band_mag_dust_apparent"]
      - ["photoz", "petroR90_r", "r_cmodel_mag_ge", "g_cmodel_mag_ge", "i_cmodel_mag_ge", "z_cmodel_mag_ge"]
    IMAGE_SIZE: 
      #- 256
      - 256
    FILTERS:
      #- ['G', 'R', 'I']
      - ['G', 'R', 'I']
      

prepare:
    #Seed for the random split algorithm
    SPLIT_SEED: 0
    #Simulation to use with the split fractions: Training, Validation, Testing
    #Note, that feature scaling is determined by the first set
    SETS:
      - ["HSC_TNG50", [0.8, 0.0, 0.1, 0.1]]  
      - ["HSC", [0.0, 0.8, 0.1, 0.1]]
    MATCHING_MAX_ITER: 200
    MATCHING_MAX_DIST: 0.05
    MATCHING_FIELDS:
      - ['z', 'i_band_mag_dust_apparent']
      - ["photoz", "i_cmodel_mag_ge"]
    #List of observables and unobservables used
    #NOTE: the names might alter from the original dataset_raw fields as prepare.py is modifying the fields
    OBSERVABLES: None
    UNOBSERVABLES:
      - 'lookback'
      - 'mass'
      - 'fraction_disk_stars'
      - 'stellar_age_2rhalf_lumw'
      - 'mass_last_maj_merger'
      - 'exsitu'
    #Split According to root descendant
    ROOT_DESCENDANT_SPLIT: True
    
data:
    #Valid range for the UNOBSERVABLE parameters; if samples are outside of this interval, results are treated as categorical 
    #Used to identify galaxies with no major mergers
    VALID_RANGE:
      - None
      - None
      - None
      - None
      - [7., 11.5]
      #- [0., 13.7]
      - None
    #Choose the Dataset Object which determines how the images are loaded and streched
    DATASET: 'TNGDataset' 
    #Target edge size of the images
    IMAGE_SIZE: 128
    #Number of data loading workers
    NUM_WORKERS: 18

train_simclr:
    #Learning Rate for the SIMCLR training
    LEARNING_RATE: 0.001
    #Weight decay for the simclr training
    L2_DECAY: 0.0001
    #Betas for the ADAM optimizer
    BETA_1: 0.9
    BETA_2: 0.999
    #Reduce the Learning rate if the validation loss has not improved for this number of epochs
    LR_PATIENCE: 2
    #Learning rate decay (i.e. the lr is multiplied by the decayfactor every milestone)
    LR_DECAY: 0.5
    #Size of batches used for the training and evaluation
    BATCH_SIZE: 32
    #Maximum number of training epochs
    NUM_EPOCHS: 10
    #Stop the training after validation loss has not improved for PATIENCE epochs
    PATIENCE: 5
    #Augmentation parameters
    AUGMENTATION_PARAMS:
        ROTATION: 10
        TRANSLATE: 0.2
        SCALE: 2.0
        FLIP: True
        GAUSSIAN_BLUR_SIGMA: [0.001, 4.0]
        NOISE_STD: [0.0, 0.05]
    
train_cinn:
    #Parameters of the Adam Optimizer
    L2_DECAY: 0.0002
    BETA_1: 0.9
    BETA_2: 0.999
    
    #Initial learning rate
    LEARNING_RATE: 0.002
    #Reduce the Learning rate if the validation loss has not improved for this number of epochs
    LR_PATIENCE: 5 
    #Learning rate decay (i.e. the lr is multiplied by the decayfactor every milestone)
    LR_DECAY: 0.5
    
    #Maximum number of training epochs
    NUM_EPOCHS: 200
    #Stop the training after validation loss has not improved for this number of epochs
    PATIENCE: 20

    #Use the simclr pretrained resnet
    USE_PRETRAINED_RESNET: True
    #Fix initialy the Resnet params during training
    FIX_RESNET_PARAMS: True
    #Unfix the RESNET params if the cINN training has reached this learning rate
    #(set to 0 if RESNET should be always fixed)
    RESNET_LR_THRESHOLD: 0.00005
    
    #Size of batches used for the training (and validation)
    BATCH_SIZE: 128

    #Level of the gaussian noise augmentation (Note that quantities are normalized)
    NOISE: 0.75
    #Number of models used in the averaging
    NUM_MODELS: 1
    
    #Augmentation parameters
    AUGMENTATION_PARAMS:
        ROTATION: 10
        TRANSLATE: 0.1
        SCALE: 1.5
        FLIP: True
        GAUSSIAN_BLUR_SIGMA: [0.1, 2.0]
        NOISE_STD: [0.0, 0.04]

model:
    #Clamp parameter of the coupling layers
    CLAMP: 1.0
    
    #Number of coupling layers
    NUM_COUPLING_LAYERS: 12
    
    #Conditional input size of the coupling layers 
    NUM_COND_NODES: 128
    
    #Width and Depth of the hidden networks in the coupling layers 
    NUM_HIDDEN_NODES: 128
    NUM_HIDDEN_LAYERS: 2
    
    #Dropout and Batch Norm between the layers in the hidden networks in the coupling layers
    DROPOUT: 0.0
    BATCH_NORM: False

    #Width and Depth of the conditional network
    NUM_HIDDEN_NODES_COND: 128    
    NUM_HIDDEN_LAYERS_COND: 2
    
    #Dropout and Batch Norm between the layers in the conditional network
    DROPOUT_COND: 0.0
    BATCH_NORM_COND: False
    
    #Parameters for the resnet 
    RESNET_DEPTH: 16
    RESNET_WIDTH: 2
    RESNET_DROPOUT: 0.3
    RESNET_REPRESENTATION_DIM: 128
    RESNET_PROJECTION_DIM: 128
    RESNET_PROJECTION_DEPTH: 3
    RESNET_NUM_CHANNELS: 3
    
    #The Number of discrete rotations the RESNET is initially equivariant
    RESNET_ROTATION_EQUIVARIANCE: 8
    #Restrict the Rotation equivariance 
    #0 = No restriction
    #1 = Restriction before the last block to N/2
    #2 = Restriction after the first block to N/2
    #3 = Restriction after the first (to N/2) and the second block (to 1)
    RESNET_ROTATION_RESTRICTION: 0
    #Flag if the RESNET
    RESNET_REFLECTION_EQUIVARIANCE: True
    #Initial Stride of the Resnet
    RESNET_INITIAL_STRIDE: 2
    
    #NOTE: If RESNET_ROTATION_EQUIVARIANCE = 1 and RESNET_REFLECTION_EQUIVARIANCE = False
    #the RESNET should be equivalent to a standard CNN

losses:
    #Kernel vor forward and backward maximum mean discrepancy loss
    mmd_kernel_type: "inverse_multiquadratic"
    mmd_forw_kernels: [[0.2, 2], [1.5, 2], [3.0, 2]]
    mmd_back_kernels: [[0.2, 0.1], [0.2, 0.5], [0.2, 2]]
    mmd_kernels: [[0.2, 0.1], [0.2, 0.5], [0.2, 2], [1.5, 2], [3.0, 2], [0.2, 3]]
    
    #Prefactor for the cINN losses
    #i.e. the overall loss is given as weighted sum with the weights given as prefactors
    lambd_max_likelihood: 1.
    lambd_mmd_forw: 0.
    lambd_mmd_back: 0.
    lambd_mae: 0.
    lambd_mse: 0.
    
    #Softmax temperature for SimCLR NCE Loss
    nce_temperature: 0.07
    
sample_posterior:
    #Number of posterior samples drawn for each galaxy in the test set
    NUM_SAMPLES: 400

peak_detection:
    EVAL_BINS: 512
    MIN_PEAK_DISTANCE: 32
    MIN_PEAK_PROMINENCE: 0.02
    MIN_PEAK_HEIGHT: 0.05